{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e86c1c57",
   "metadata": {},
   "source": [
    "# Import Dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a023a805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix,precision_score,recall_score,f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import warnings\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60a15efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "703e7cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_col_names=[\"Buying\",\"Maintenance Cost\",\"Doors\",\"Persons\",\"Lug_Boot\",\"Safety\",\"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec94cf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.index = np.arange(1, len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "686a432d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\User\\\\Desktop\\\\Data Science\\\\Car-Data-Evaluation\\\\car_evaluation.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mUsers\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mUser\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mDesktop\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mData Science\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mCar-Data-Evaluation\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mcar_evaluation.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\io\\common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\User\\\\Desktop\\\\Data Science\\\\Car-Data-Evaluation\\\\car_evaluation.csv'"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"C:\\\\Users\\\\User\\\\Desktop\\\\Data Science\\\\Car-Data-Evaluation\\\\car_evaluation.csv\",header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f4200f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.index = df.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d6f6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['Buying', 'Maintenance Cost', 'Doors', 'Persons', 'Lug_Boot', 'Safety', 'Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9053582b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16aa2eea",
   "metadata": {},
   "source": [
    "Rows: 1728,\n",
    "Features: 7,\n",
    "Target Feature: class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "addeeaa5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mtail(\u001b[38;5;241m4\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.tail(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de8bf521",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c83977",
   "metadata": {},
   "source": [
    "Renaming the Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc54c81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_def=[]\n",
    "for row in df['Class']:\n",
    "    if row =='unacc':\n",
    "        class_def.append('Unacceptable')\n",
    "    elif row == 'acc':\n",
    "        class_def.append('Acceptable')\n",
    "    elif row == 'good':\n",
    "        class_def.append('Good')\n",
    "    elif row == 'vgood':\n",
    "        class_def.append('Very Good')\n",
    "    else:\n",
    "        class_def.append('Failed')\n",
    "df['Class'] = class_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276e1b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "safe=[]\n",
    "\n",
    "for row in df['Safety']:\n",
    "    if row =='low':\n",
    "        safe.append('Low')\n",
    "    elif row == 'med':\n",
    "        safe.append('Medium')\n",
    "    elif row == 'high':\n",
    "        safe.append('High')\n",
    "df['Safety'] = safe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455d0094",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lug=[]\n",
    "\n",
    "for row in df['Lug_Boot']:\n",
    "    if row =='small':\n",
    "        Lug.append('Low')\n",
    "    elif row == 'med':\n",
    "        Lug.append('Medium')\n",
    "    elif row == 'big':\n",
    "        Lug.append('Big')\n",
    "df['Lug_Boot'] = Lug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219b4ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Buy=[]\n",
    "\n",
    "for row in df['Buying']:\n",
    "    if row =='vhigh':\n",
    "        Buy.append('Very High')\n",
    "    elif row == 'med':\n",
    "        Buy.append('Medium')\n",
    "    elif row == 'low':\n",
    "        Buy.append('Low')\n",
    "    elif row == 'high':\n",
    "        Buy.append('High')\n",
    "df['Buying'] = Buy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb3f8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "M_cost=[]\n",
    "\n",
    "for row in df['Maintenance Cost']:\n",
    "    if row =='vhigh':\n",
    "        M_cost.append('Very High')\n",
    "    elif row == 'med':\n",
    "        M_cost.append('Medium')\n",
    "    elif row == 'low':\n",
    "        M_cost.append('Low')\n",
    "    elif row == 'high':\n",
    "        M_cost.append('High')\n",
    "df['Maintenance Cost'] = M_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0cd77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605a6f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[20:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8919de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31983fb",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837e70ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in my_col_names:\n",
    "    values=df[col].value_counts()\n",
    "    print(\"Column Names is\",col)\n",
    "    plt.ylabel('Distribution by ' + col)\n",
    "    values.plot(kind=\"bar\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bad652",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8863d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = {\n",
    "  \"data\": [\n",
    "    {\n",
    "      \"values\": [1210,384,69,65],\n",
    "      \"labels\": [\n",
    "        \"Unacceptable\",\n",
    "        \"Acceptable\",\n",
    "        \"Good\",\n",
    "        \"Very Good\"\n",
    "      ],\n",
    "      \"domain\": {\"column\": 0},\n",
    "      \"name\": \"Car Evaluation\",\n",
    "      \"hoverinfo\":\"label+percent+name\",\n",
    "      \"hole\": .4,\n",
    "      \"type\": \"pie\"\n",
    "    }],\n",
    "  \"layout\": {\n",
    "        \"title\":\"Distribution of Evaluated Cars\",\n",
    "        \"grid\": {\"rows\": 1, \"columns\": 1},\n",
    "        \"annotations\": [\n",
    "            {\n",
    "                \"font\": {\n",
    "                    \"size\": 18\n",
    "                },\n",
    "                \"showarrow\": False,\n",
    "                \"text\": \"\",\n",
    "                \"x\": 0.1,\n",
    "                \"y\": 0.1\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "py.iplot(fig, filename='cars_donut')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f922c91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grp_brplt(col1):\n",
    "    \n",
    "    df1 = df.groupby(['Class',col1]).size().to_frame('total').reset_index()\n",
    "    \n",
    "    plt.figure(figsize=(6,4))\n",
    "    ax=plt.subplot()\n",
    "    ax = sns.barplot(data=df1, x=df1[col1], y=df1[\"total\"], hue=df1[\"Class\"])\n",
    "    \n",
    "    for p in ax.patches:\n",
    "        ax.annotate(format(p.get_height(), '.1f'), \n",
    "                       (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                       ha = 'center', va = 'center', \n",
    "                       xytext = (0, 9), \n",
    "                       textcoords = 'offset points')\n",
    "\n",
    "    ax.set_title('Distribution of ' +col1+ ' per target variable', fontsize=20)\n",
    "    ax.legend(loc='center right', bbox_to_anchor=(1.25, 0.5), ncol=1, title='y')\n",
    "    return ax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990a4bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_brplt(\"Maintenance Cost\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81736d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_brplt(\"Buying\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0719a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_brplt(\"Persons\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d8080d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_brplt(\"Safety\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5538bf32",
   "metadata": {},
   "source": [
    "# Checking data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f129245a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a76a28",
   "metadata": {},
   "source": [
    "# Checking Null Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ec731b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32eb146",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.isnull())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd503bc",
   "metadata": {},
   "source": [
    "# Frequency distribution of values in variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1700ffc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(df):\n",
    "  for i in df.columns[1:]:\n",
    "    print(\"Feature: {} with {} Levels\".format(i,df[i].unique()))\n",
    "\n",
    "show(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73391de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in my_col_names:\n",
    "    print(\"-\" * 40)\n",
    "    print(\"Column Name Is\",col)\n",
    "    print(\"-\" * 40)\n",
    "    print(df[col].value_counts())  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c0d745",
   "metadata": {},
   "source": [
    "Summary of variables"
   ]
  },
  {
   "cell_type": "raw",
   "id": "25c72db2",
   "metadata": {},
   "source": [
    "There are 7 variables in the dataset.[buying, maint, doors, persons, lug_boot, safety and class].\n",
    "Target variable is Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba0278e",
   "metadata": {},
   "source": [
    "# Checking Unique Value Per Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ade7aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in my_col_names:\n",
    "    print(\"-------------------\")\n",
    "    print(\"Column Name Is\",col)\n",
    "    print(\"-------------------\")\n",
    "    print(df[col].unique())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd87aad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features=['Buying','Maintenance Cost','Doors','Persons','Lug_Boot','Safety']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad6d6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in categorical_features:\n",
    "    print('Feature: ',i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef57bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in categorical_features:\n",
    "    print('Feature: ',i)\n",
    "    print(\"----------------------\")\n",
    "    print(df[i].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d0ac30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f631f42",
   "metadata": {},
   "source": [
    "If the model perdicts all input as unacc then it will be 70% accurate which is wrong.\n",
    "Hence we cannot conclude a model's performance just by accuracy.\n",
    "\n",
    "To overcome this I'm oversampling it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ea9c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df[\"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba928fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop([\"Class\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1e258a",
   "metadata": {},
   "outputs": [],
   "source": [
    "le=LabelEncoder()\n",
    "for i in categorical_features:\n",
    "    x[i]=le.fit_transform(x[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fc9809",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6890fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2936f0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest=train_test_split(x,target,test_size=0.2,random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fad725",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6adbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6e0180",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51a5d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ac0a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=[]\n",
    "f1=[]\n",
    "model=[]\n",
    "precision=[]\n",
    "support=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c514aa4",
   "metadata": {},
   "source": [
    "# Check for overfitting and underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9562b399",
   "metadata": {},
   "source": [
    "Here, the Training Accuracy score is 0.69030 Where the Testing Accuracy to be 0.6994 Both values are quite comparable. So,No need to Overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccd8215",
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7457cf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_parametrics(y_train,yp_train,y_test,yp_test):\n",
    "  print(\"--------------------------------------------------------------------------\")\n",
    "  print(\"Classification Report for Train Data\")\n",
    "  print(classification_report(y_train, yp_train))\n",
    "  print(\"Classification Report for Test Data\")\n",
    "  print(classification_report(y_test, yp_test))\n",
    "  print(\"--------------------------------------------------------------------------\")\n",
    "  # Accuracy\n",
    "  print(\"Accuracy on Train Data is: {}\".format(round(accuracy_score(y_train,yp_train),2)))\n",
    "  print(\"Accuracy on Test Data is: {}\".format(round(accuracy_score(y_test,yp_test),2)))\n",
    "  print(\"--------------------------------------------------------------------------\")\n",
    "  # Precision\n",
    "  print(\"Precision on Train Data is: {}\".format(round(precision_score(y_train,yp_train,average = \"weighted\"),2)))\n",
    "  print(\"Precision on Test Data is: {}\".format(round(precision_score(y_test,yp_test,average = \"weighted\"),2)))\n",
    "  print(\"--------------------------------------------------------------------------\")\n",
    "  # Recall \n",
    "  print(\"Recall on Train Data is: {}\".format(round(recall_score(y_train,yp_train,average = \"weighted\"),2)))\n",
    "  print(\"Recall on Test Data is: {}\".format(round(recall_score(y_test,yp_test,average = \"weighted\"),2)))\n",
    "  print(\"--------------------------------------------------------------------------\")\n",
    "  # F1 Score\n",
    "  print(\"F1 Score on Train Data is: {}\".format(round(f1_score(y_train,yp_train,average = \"weighted\"),2)))\n",
    "  print(\"F1 Score on Test Data is: {}\".format(round(f1_score(y_test,yp_test,average = \"weighted\"),2)))\n",
    "  print(\"--------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183b4708",
   "metadata": {},
   "source": [
    "# LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018a5c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(xtrain,ytrain)\n",
    "\n",
    "trainpredict = lr.predict(xtrain)\n",
    "testpredict = lr.predict(xtest)\n",
    "\n",
    "evaluation_parametrics(ytrain,trainpredict,ytest,testpredict)\n",
    "\n",
    "accuracy.append(np.round(accuracy_score(ytest,testpredict),2))\n",
    "\n",
    "f1.append(np.round(f1_score(ytest,testpredict,average='weighted'),2))\n",
    "\n",
    "precision.append(np.round(precision_score(ytrain,trainpredict,average = \"weighted\"),2))\n",
    "\n",
    "model.append('Logistic Regression')\n",
    "cm = confusion_matrix(ytest, testpredict)\n",
    "print(\"Confusion matrix\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3efff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1,precision,accuracy,model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34369b65",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4415f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN = KNeighborsClassifier(n_neighbors = 9)\n",
    "KNN.fit(xtrain, ytrain)\n",
    "\n",
    "trainpredict = KNN.predict(xtrain)\n",
    "testpredict = KNN.predict(xtest)\n",
    "\n",
    "evaluation_parametrics(ytrain,trainpredict,ytest,testpredict)\n",
    "\n",
    "accuracy.append(np.round(accuracy_score(ytest,testpredict),2))\n",
    "\n",
    "f1.append(np.round(f1_score(ytest,testpredict,average='weighted'),2))\n",
    "\n",
    "precision.append(np.round(precision_score(ytrain,trainpredict,average = \"weighted\"),2))\n",
    "\n",
    "model.append('K-Neighbors Classifier')\n",
    "cm = confusion_matrix(ytest, testpredict)\n",
    "print(\"Confusion matrix\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2b61ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1,precision,accuracy,model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5587d156",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e3d788",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_CL = RandomForestClassifier()\n",
    "RF_CL.fit(xtrain, ytrain)\n",
    "\n",
    "trainpredict = RF_CL.predict(xtrain)\n",
    "testpredict = RF_CL.predict(xtest)\n",
    "\n",
    "evaluation_parametrics(ytrain,trainpredict,ytest,testpredict)\n",
    "\n",
    "accuracy.append(np.round(accuracy_score(ytest,testpredict),2))\n",
    "f1.append(np.round(f1_score(ytest,testpredict,average='weighted'),2))\n",
    "\n",
    "precision.append(np.round(precision_score(ytrain,trainpredict,average = \"weighted\"),2))\n",
    "model.append('Random Forest')\n",
    "cm = confusion_matrix(ytest, testpredict)\n",
    "print(\"Confusion matrix\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a99be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1,precision,accuracy,model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893a5599",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f859dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dst=tree.DecisionTreeClassifier(criterion='entropy')\n",
    "dst.fit(xtrain,ytrain)\n",
    "\n",
    "trainpredict = dst.predict(xtrain)\n",
    "testpredict = dst.predict(xtest)\n",
    "\n",
    "evaluation_parametrics(ytrain,trainpredict,ytest,testpredict)\n",
    "\n",
    "accuracy.append(np.round(accuracy_score(ytest,testpredict),2))\n",
    "f1.append(np.round(f1_score(ytest,testpredict,average='weighted'),2))\n",
    "\n",
    "precision.append(np.round(precision_score(ytrain,trainpredict,average = \"weighted\"),2))\n",
    "\n",
    "model.append('Decision Tree Classifier')\n",
    "cm = confusion_matrix(ytest, testpredict)\n",
    "print(\"Confusion matrix\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dc844b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1,precision,accuracy,model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3caf1bf",
   "metadata": {},
   "source": [
    "# Support Vector Machine(Linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f1c72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel = 'linear', random_state = 0)\n",
    "clf.fit(xtrain, ytrain)\n",
    "\n",
    "trainpredict = clf.predict(xtrain)\n",
    "testpredict = clf.predict(xtest)\n",
    "\n",
    "evaluation_parametrics(ytrain,trainpredict,ytest,testpredict)\n",
    "\n",
    "accuracy.append(np.round(accuracy_score(ytest,testpredict),2))\n",
    "f1.append(np.round(f1_score(ytest,testpredict,average='weighted'),2))\n",
    "\n",
    "precision.append(np.round(precision_score(ytrain,trainpredict,average = \"weighted\"),2))\n",
    "\n",
    "model.append('Support Vector Machine(Linear)')\n",
    "cm = confusion_matrix(ytest, testpredict)\n",
    "print(\"Confusion matrix\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df9eb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1,precision,accuracy,model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c900d0a",
   "metadata": {},
   "source": [
    "# Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa689d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "GNB = GaussianNB()\n",
    "GNB.fit(xtrain, ytrain)\n",
    "\n",
    "trainpredict = GNB.predict(xtrain)\n",
    "testpredict = GNB.predict(xtest)\n",
    "\n",
    "evaluation_parametrics(ytrain,trainpredict,ytest,testpredict)\n",
    "\n",
    "accuracy.append(np.round(accuracy_score(ytest,testpredict),2))\n",
    "f1.append(np.round(f1_score(ytest,testpredict,average='weighted'),2))\n",
    "\n",
    "precision.append(np.round(precision_score(ytrain,trainpredict,average = \"weighted\"),2))\n",
    "model.append('Gaussian Naive Bayes)')\n",
    "\n",
    "cm = confusion_matrix(ytest, testpredict)\n",
    "print(\"Confusion matrix\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3502a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1,precision,accuracy,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f957aff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(f1), len(accuracy), len(model)),print(len(precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4a81d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output=pd.DataFrame({'Model':model,\n",
    "                    'Accuracy':accuracy,\n",
    "                    'Precision':precision,\n",
    "                    'F1 score':f1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae0a6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c1eb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.sort_values(by=['Accuracy'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e18b627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.graph_objs as go\n",
    "\n",
    "# model=['Logistic Regression', 'Support Vector Machine','Decision Tree Classifier','KNN','GNB',\"Random Forest\" ]\n",
    "\n",
    "# fig = go.Figure(data=[\n",
    "#     go.Bar(name='f1_score', x=model, y=[lr,clf,dst,KNN,GNB,RF_CL])])\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b91b4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=RF_CL.predict(x)\n",
    "y_pred[[200,100,1400,1723]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8c5abe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
